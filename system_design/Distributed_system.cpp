# Distributed Systems - Complete Guide

## What Is a Distributed System?

A **Distributed System** is a system where:
- Multiple computers (nodes/servers) work together as one unified system to achieve a common goal
- To the user, it appears as ONE system, not multiple separate components

### Real-World Analogy: Juice Stall

Imagine you're' running a juice stall:
- One person takes orders
- One person cuts fruits
- One person blends
- One person delivers

To the customer ‚Üí It feels like ONE shop, not four people doing different tasks.

**That's' a distributed system!**

---

## Why Do We Need Distributed Systems?

| Need | Reason |
|------|--------|
| **Scalability** | One machine can't' handle millions of users |
| **Fault Tolerance** | If one server fails, the system continues working |
| **Performance** | Work is processed in parallel ‚Üí Faster results |
| **High Availability** | Available 24√ó7 without downtime |

---

## Core Features of Distributed Systems

| Feature | Meaning |
|---------|---------|
| **Decentralization** | No single machine controls everything |
| **Replication** | Data exists in multiple copies |
| **Consistency Handling** | Keep all copies synchronized |
| **Communication** | Machines communicate via network (HTTP, RPC, gRPC) |
| **Transparency** | User doesn't' see the underlying complexity |

### Easy Analogy: Pizza Shop Chain

Imagine Pizza Hut:
- **One store** ‚Üí OK for 10 customers
- **For 1 million customers** ‚Üí One store cannot handle

**Solution:** Open multiple branches:
- Bangalore branch
- Kolkata branch
- Mumbai branch

All branches follow:
- ‚úî Same menu
- ‚úî Same pricing
- ‚úî Same system

To the customer ‚Üí Looks like one Pizza Hut, but actually distributed across multiple locations.

---

## Important Concepts in Distributed Systems

### 1Ô∏è‚É£ Load Balancer

**Purpose:** Decides which server handles which request

Think of it as a gatekeeper deciding which counter is free.

**Example:**
```
User request ‚Üí Load balancer ‚Üí Server A or B or C
```

### 2Ô∏è‚É£ Replication

**Purpose:** Same data stored in multiple servers so the system doesn't' fail

**Example:** When you upload a photo to Instagram ‚Üí It is stored in:
- Mumbai server
- Singapore backup
- US replication

So even if 1 server fails ‚Üí data remains safe.

### 3Ô∏è‚É£ Sharding (Partitioning)

**Purpose:** Split data into parts to improve performance

**Example:**
- Usernames A‚ÄìM stored in Database 1
- Usernames N‚ÄìZ stored in Database 2

### 4Ô∏è‚É£ Consistency

**Purpose:** All servers should agree on the same data

Sometimes systems prioritize speed over consistency (CAP theorem logic).

**Example:** WhatsApp message delivery:
- Shows ‚úî (sent)
- Then after a few ms shows ‚úî‚úî (delivered)
- Then after sync shows blue ‚úî‚úî (read)

Updates come gradually ‚Üí That's' **eventual consistency**.

---

## Scaling Strategies

### Vertical Scaling (Scaling UP)

**Meaning:** Increase the power of a single machine

**What you upgrade:**
- CPU
- RAM
- Storage
- GPU

**Example:** Your laptop lags ‚Üí You increase RAM from 8GB ‚Üí 16GB
- Same server, more power

### Horizontal Scaling (Scaling OUT)

**Meaning:** Add more machines instead of upgrading one

Requires distributed coordination and consistency management.

**Example:** Instead of using one supercomputer, use:
- Server 1
- Server 2
- Server 3
- ... all connected via distributed load balancing

**üí° Pro Tip:** Start with vertical scaling, then move to horizontal scaling as users increase.

---

## Load Balancing

### What Is Load Balancing?

**Load balancing** is the technique of distributing incoming requests across multiple servers so no single server gets overloaded (uses consistent hashing).

**Formula:** 
- `X/n = 1/n` (where X is servers and n are users)
- `x1 = m % n` (where m is the user)

**Simple explanation:** Instead of one person doing 100 tasks, divide it among many people so everyone works smoothly.

### Architecture:
```
Client ‚Üí Load Balancer ‚Üí Server 1
                      ‚Üí Server 2
                      ‚Üí Server 3
```

---

## Types of Load Balancing Algorithms

### 1Ô∏è‚É£ Round Robin

**How it works:** Requests go to servers in order: A ‚Üí B ‚Üí C ‚Üí A ‚Üí B ‚Üí C ‚Üí A‚Ä¶

**Example:**

| Request | Server |
|---------|--------|
| R1 | A |
| R2 | B |
| R3 | C |
| R4 | A |
| R5 | B |
| R6 | C |

**üìç Use when:** All servers have equal power and tasks are similar.

---

### 2Ô∏è‚É£ Weighted Round Robin

**How it works:** Stronger servers (more RAM/CPU) get more load

**Example:**
- Server A weight = 3
- Server B weight = 1

**Distribution:** A, A, A, B, A, A, A, B...

---

### 3Ô∏è‚É£ Least Connections

**How it works:** Assign request to the server with the fewest active users

**Example:**

| Server | Current Connections |
|--------|---------------------|
| A | 10 |
| B | 4 |
| C | 7 |

Next request goes to ‚Üí **Server B**

**üìç Use in:** Chat apps, video calls where connection duration varies.

---

### 4Ô∏è‚É£ IP Hashing

**How it works:** Same client always goes to the same server using a hashing function

**Useful for:**
- ‚úî Session-based apps
- ‚úî Gaming servers
- ‚úî Sticky sessions (shopping cart)

**Example:**
- User1 IP hashed ‚Üí Server A
- User2 IP hashed ‚Üí Server B
- Every time User1 returns ‚Üí Still Server A

---

### 5Ô∏è‚É£ Health-Based Load Balancing (Failover)

**How it works:** If one server is down, load balancer skips it

**Example:**

| Server | Status |
|--------|--------|
| A | üü¢ Alive |
| B | üî¥ Down |
| C | üü¢ Alive |

Requests ‚Üí A, C, A, C‚Ä¶ (B ignored)

---

## Load Balancing Implementation

### Basic Round Robin (Pseudocode)

```cpp
class LoadBalancer {
private:
    vector<Server> servers;
    int index = 0;

public:
    void addServer(Server server) {
        servers.push_back(server);
    }

    Server getNextServer() {
        Server chosen = servers[index];
        index = (index + 1) % servers.size();
        return chosen;
    }
};

// Usage
LoadBalancer lb;
lb.addServer(Server("A"));
lb.addServer(Server("B"));
lb.addServer(Server("C"));
lb.getNextServer(); // A
lb.getNextServer(); // B
lb.getNextServer(); // C
lb.getNextServer(); // A again
```

---

### Consistent Hashing for Load Balancing

**Why needed:** Normal hashing breaks when servers change. Consistent hashing survives changes by only moving a small set of keys.

**Use case:** When servers are added or removed, this approach minimizes disruption.

```cpp
class ConsistentHashing {
    map<int, string> ring;  // position -> server
    
public:
    void addServer(string serverName) {
        int hashValue = hash(serverName);
        ring[hashValue] = serverName;
    }
    
    string getServer(string key) {
        int hashValue = hash(key);
        auto it = ring.lower_bound(hashValue);
        if(it == ring.end())
            return ring.begin()->second; // wrap around
        return it->second;
    }
};

// Usage
ConsistentHashing ch;
ch.addServer("A");
ch.addServer("B");
ch.addServer("C");
cout << ch.getServer("User7"); // maybe "B"
```

---

## CAP Theorem

### What CAP Theorem Tells Us:

In a distributed system, you can only guarantee **2 out of 3** things at the same time, not all 3.

| Letter | Meaning |
|--------|---------|
| **C** ‚Äî Consistency | Everyone sees the same data at the same time |
| **A** ‚Äî Availability | System always responds, even if some parts fail |
| **P** ‚Äî Partition Tolerance | System still works even if network breaks between servers |

### Important Note: Partition Tolerance Is Mandatory

We always have **P** in distributed systems.

So real systems choose: **(C + P) OR (A + P)**

---

### üß† CP (Consistency + Partition Tolerance)

**Priority:** System prefers accurate data over availability

**Examples:**
- Banking systems
- Stock trading
- SQL clusters

---

### ‚ö° AP (Availability + Partition Tolerance)

**Priority:** System prefers working fast even if data is temporarily inconsistent

**Examples:**
- Instagram likes
- Messaging apps
- NoSQL systems

---

### When to Choose What?

- **When correctness must be guaranteed ‚Üí CP**
- **When speed and uptime is priority ‚Üí AP**

**Note:** Data sharding uses the concepts of CAP theorem.

---

## Data Sharding

### What Is Sharding?

**Sharding** means splitting a large database into smaller pieces (called shards) so data is stored and processed more efficiently.

Instead of one giant DB doing all work, you divide data across multiple DBs.

### Real-World Analogy

Imagine you have 10,000 exam papers and only ONE teacher checking.
- She will take days üò≠

**Solution:** Divide papers among 5 teachers:

| Teacher | Papers |
|---------|--------|
| A | Roll 1‚Äì2000 |
| B | Roll 2001‚Äì4000 |
| C | Roll 4001‚Äì6000 |
| D | Roll 6001‚Äì8000 |
| E | Roll 8001‚Äì10000 |

Now all work happens in parallel ‚Üí Much faster!

**This division = Sharding**

**Note:** If failure occurs, use master-slave solution for recovery.

---

## Message Queue

### What Is a Message Queue?

A **Message Queue** is a system that stores messages and delivers them asynchronously from one service to another.

**In simple words:**
One service sends a message ‚Üí Queue stores it ‚Üí Another service processes it later.

### Key Terms

| Term | Meaning |
|------|---------|
| **Producer** | Service that sends messages |
| **Queue** | Temporary storage |
| **Consumer** | Service that reads/processes messages |
| **Broker** | The queue system (RabbitMQ, Kafka, SQS) |
| **Acknowledgment** | Consumer confirms message processed |
| **Retry / Dead-letter queue** | Failed messages stored here |

### Workflow

```
Producer ‚Üí Send Message ‚Üí Queue stores ‚Üí Consumer pulls ‚Üí Processes ‚Üí Sends ACK ‚Üí Removes message
```

A **broker** (like Kafka) handles communication between services.

---

### How It Works in Practice

When we make a request to the server:
1. Request is added to a message queue
2. A **notifier component** monitors server health by sending signals every 10 seconds
   - If a server doesn't' respond ‚Üí Assumed to be dead
3. Notifier checks the database to see if work is completed and marks it as done
4. If a server fails, notifier verifies in the database whether the request was completed
5. If not completed ‚Üí Load balancer assigns the request to another available server

---

## Architecture Patterns

### Monolithic Architecture

**Definition:** Everything (UI, business logic, database logic, API, payments, notifications, authentication, etc.) is inside one single application/codebase.

#### Restaurant Analogy

Imagine a big restaurant with:
- Chefs
- Cashier
- Waiters
- Cleaning staff
- Delivery staff

**BUT‚Ä¶** They are all locked in one room and must work together.

**Problem:** If one person is slow ‚Üí Everyone gets delayed.

---

### Microservices Architecture

**Definition:** Application is broken into small independent services that communicate over a network.

Each service has:
- Its own logic
- Its own deployment
- Often its own database

#### Same Restaurant, Different Approach

- Chefs work in kitchen
- Cashier works separately
- Delivery staff = separate team
- Cleaning = separate team

**Benefits:**
- ‚úî If delivery team fails ‚Üí Kitchen still works
- ‚úî Teams scale independently (hire more delivery staff if demand grows)

---

### Comparison: Monolith vs Microservices

| Area | Monolith | Microservices |
|------|----------|---------------|
| **Framework** | Django, Laravel, Rails | Spring Boot, FastAPI, Go, Node services |
| **Database** | Single MySQL/Postgres | Multiple DBs (MongoDB, Redis, Cassandra, PostgreSQL) |
| **Communication** | Function calls | REST, gRPC, Kafka, RabbitMQ |
| **Deployment** | One EC2 server | Kubernetes / Docker |

---

## Caching

### What is Cache?

**Cache** = Fast temporary storage used to store frequently accessed data so we don't' repeatedly hit slow backend systems (like databases).

**Simple definition:** Cache = "Shortcut memory" for your system.

### Teacher Analogy

Imagine you are a teacher.

Student repeatedly asks: "Ma'am, what is today's date?"

Instead of telling every time by checking the calendar‚Ä¶ **You write the date on the board.**

Now 100 students can read it instantly.

**That board = Cache**

---

### Why Caching in Distributed Systems?

Because:
- DB queries are slow
- Network latency exists
- Millions of users may request the same data

---

## Types of Cache in Distributed Systems

### 1Ô∏è‚É£ Local Cache (In-App Cache)

**Storage:** In the application's' RAM

**Flow:**
```
User ‚Üí Service ‚Üí Local Cache ‚Üí (maybe DB)
```

**Pros:**
- ‚úî Very fast

**Cons:**
- ‚ùå Not shared across servers
- ‚ùå Inconsistent in multi-server architecture

**Examples:** In-memory maps like Guava Cache, Caffeine

---

### 2Ô∏è‚É£ Distributed Cache (Shared Cache)

**Storage:** All servers use the same cache store

**Architecture:**
```
Server A ‚îÄ‚îÄ‚îÄ‚îê
Server B ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚Üí Redis / Memcached
Server C ‚îÄ‚îÄ‚îÄ‚îò
```

**Pros:**
- ‚úî Consistent
- ‚úî Shared across all servers
- ‚úî Highly scalable

**Examples:** Redis, Memcached, Hazelcast

---

### 3Ô∏è‚É£ CDN Cache (Global Edge Cache)

**Use case:** Static content delivery
- Images
- JS/CSS files
- Videos

**How it works:** CDN puts data closer to users geographically

**Example:** Netflix distributing videos globally

**Note:** For more details and diagrams, visit file: `6.system_design_pattern.drawio`

---

## Content Delivery Network (CDN)

### What is a CDN?

**CDN (Content Delivery Network)** is a globally distributed network of servers that deliver content (images, videos, CSS, JS, PDFs, etc.) to users from the nearest location for faster access.

**Short version:** Instead of fetching content from a far-away origin server, CDN serves it from a nearby server to reduce load time.

### Ice Cream Factory Analogy

Imagine one ice cream factory in Delhi serving all of India.

Someone in Kerala orders ice cream:
- ‚ùå It will take hours ‚Üí Ice cream melts
- ‚ùå Customer becomes angry üò≠

**Solution:** Factory creates small ice cream storage shops in:
- Kerala
- Bangalore
- Mumbai
- Kolkata
- Chennai

Now users get ice cream instantly from the nearest store üç¶‚ö°

**Those storage shops = CDN Edge Servers**

---

### CDN Workflow

```
User Request ‚Üí CDN Node Nearby ‚Üí (If cached: return immediately)
                               |
                               ‚Üì
                        If not cached ‚Üí Origin Server ‚Üí Cache ‚Üí Return
```

**Note:** In CDN, generally only static files are cached (images, files, HTML, CSS, APIs, videos)

---

### CDN Architecture

```
           ORIGIN SERVER (Main source)
                        |
                        ‚Üì
             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
             ‚îÇ CONTENT DELIVERY NETWORK ‚îÇ
             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            /               |                 \
     Edge Server Asia   Edge Server Europe  Edge Server US
         ‚Üì                   ‚Üì                  ‚Üì
  Users in India      Users in Germany     Users in Florida
  get data faster     get data faster      get data faster
```

---

## Event-Driven Architecture

### What Is Event-Driven Architecture?

In **EDA**, systems communicate using events instead of direct requests.

**Simple explanation:** Something happens ‚Üí That event is published ‚Üí Other services react to it.

### Basic Flow

```
Producer ‚Üí Event Broker ‚Üí Consumers
```

### Key Roles

| Role | Meaning |
|------|---------|
| **Producer** | Service that creates/publishes events |
| **Broker** | System that stores and routes events (Kafka, RabbitMQ, SNS, Redis Streams) |
| **Consumer** | Service(s) that process events |

---

### School Bell Analogy

Imagine a school bell üîî rings.

**The bell is the event.**

Once the bell rings:
- Students stop class
- Teacher ends lecture
- Peon opens gate
- Canteen prepares lunch

**Important:** The bell didn't tell each person what to do. It just announced an event ‚Üí Everyone reacted.

**This is an event-driven system!**

**Note:** An event is something that happened in the system.
- **Example:** `OrderPlaced`

---

### Comparing Event-Driven with Publisher-Subscriber Pattern

```
Publisher ---> Broker Topic ---> Subscriber 1
                             ---> Subscriber 2
                             ---> Subscriber 3
```

---

**End of Guide**